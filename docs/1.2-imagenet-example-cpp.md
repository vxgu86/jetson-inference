

# Coding Your Own Image Recognition Program (C++)

开始创建一个用于图像识别的新程序[`my-recognition`](../examples/my-recognition/my-recognition.cpp)，该程序将在本库之外作为独立项目存在，如果希望在自己的项目应用中使用jetson-inference库，也可以按照这里的步骤进行操作。

所有文件文件[`examples/my-recognition`](../examples/my-recognition) 也在代码目录中。

## Setting up the Project

首先创建目录`~/my-recognition`，在终端窗口中执行如下操作：

``` bash
$ mkdir ~/my-recognition
$ cd ~/my-recognition
$ touch my-recognition.cpp
$ touch CMakeLists.txt
$ wget https://github.com/dusty-nv/jetson-inference/raw/master/data/images/black_bear.jpg 
$ wget https://github.com/dusty-nv/jetson-inference/raw/master/data/images/brown_bear.jpg
$ wget https://github.com/dusty-nv/jetson-inference/raw/master/data/images/polar_bear.jpg 
```

使用wget下载测试图像到文件夹中，接下来将程序代码添加到创建的源文件中。

## Source Code

打开`my-recognition.cpp` (例如`gedit my-recognition.cpp`).  

首先，我们要使用[`imageNet`](../c/imageNet.h)类：

#### 1 Includes

``` cpp
// include imageNet header for image recognition
#include <jetson-inference/imageNet.h>

// include loadImage header for loading images
#include <jetson-utils/loadImage.h>
```
> **note**:  [代码编译](building-repo-2.md#compiling-the-project)代码编译时，这些头文件在执行`sudo make install`指令时安装到了`/usr/local/include`。 install是必要步骤，否则将提示找不到这些头文件。

#### 2 声明 main() 并解析命令行

声明`main()`并在命令行以参数形式接收需要分类的图片文件名。  

``` cpp
// main entry point
int main( int argc, char** argv )
{
	// a command line argument containing the image filename is expected,
	// so make sure we have at least 2 args (the first arg is the program)
	if( argc < 2 )
	{
		printf("my-recognition:  expected image filename as argument\n");
		printf("example usage:   ./my-recognition my_image.jpg\n");
		return 0;
	}

	// retrieve the image filename from the array of command line args
	const char* imgFilename = argv[1];
```

这就相当于执行了

``` bash
$ ./my-recognition my_image.jpg
```

#### 3 从磁盘加载图像

声明一些变量来存储图像的尺寸和指向图像内存的指针，然后使用[`loadImageRGBA()`](https://github.com/dusty-nv/jetson-utils/blob/master/loadImage.h#L30)函数从磁盘加载图像。

``` cpp
	// these variables will be used to store the image data and dimensions
	// the image data will be stored in shared CPU/GPU memory, so there are
	// pointers for the CPU and GPU (both reference the same physical memory)
	float* imgCPU    = NULL;    // CPU pointer to floating-point RGBA image data
	float* imgCUDA   = NULL;    // GPU pointer to floating-point RGBA image data
	int    imgWidth  = 0;       // width of the image (in pixels)
	int    imgHeight = 0;       // height of the image (in pixels)
		
	// load the image from disk as float4 RGBA (32 bits per channel, 128 bits per pixel)
	if( !loadImageRGBA(imgFilename, (float4**)&imgCPU, (float4**)&imgCUDA, &imgWidth, &imgHeight) )
	{
		printf("failed to load image '%s'\n", imgFilename);
		return 0;
	}
```

加载的图像将存储在映射到CPU和GPU的共享内存中，有两个可用于访问在CPU和GPU地址空间的指针，但实际上在内存中只有一份图像数据。CPU和GPU指针都解析为相同的物理内存，而无需执行内存副本（即 `cudaMemcpy()`）。

当从CPU代码访问图像时，应该使用`imgCPU`指针；当从GPU上的CUDA内核访问图像时，应该使用`imgCUDA`指针。由于我们在示例中的操作将使用TensorRT在GPU上运行，因此我们将使用`imgCUDA`指针。

图像以`float4` RGBA格式加载，像素值介于0.0和255.0之间。 

#### 4 加载图像识别网络

使用[`imageNet::Create()`](../c/imageNet.h#L70)函数，下面的代码将加载用TensorRT优化过的GoogleNet模型。该模型在ImageNet ILSVRC12数据集上进行了预训练，该数据集可识别多达[1000 种不同类别的物体](../data/networks/ilsvrc12_synset_words.txt)，如不同种类的水果和蔬菜，许多不同种类的动物，以及日常物体，如车辆，办公家具，运动器材等。  

``` cpp
	// load the GoogleNet image recognition network with TensorRT
	// you can use imageNet::RESNET_18 to load ResNet-18 instead
	imageNet* net = imageNet::Create(imageNet::GOOGLENET);

	// check to make sure that the network model loaded properly
	if( !net )
	{
		printf("failed to load image recognition network\n");
		return 0;
	}
```

这里也可以改变传递给参数的网络标识 `imageNet::Create()`来加载不同的网络，[这张表](imagenet-console-2.md#downloading-other-classification-models)罗列了很多可用的网络，如ResNet-18 (`imageNet::RESNET_18`)。
AlexNet模型也在ILSVRC12的1000类对象上进行了训练。

#### 5 对图像进行分类

接下来用[`imageNet::Classify()`](../c/imageNet.h#L103) 函数来调用图像识别网络进行图像分类。

``` cpp
	// this variable will store the confidence of the classification (between 0 and 1)
	float confidence = 0.0;

	// classify the image with TensorRT on the GPU (hence we use the CUDA pointer)
	// this will return the index of the object class that the image was recognized as (or -1 on error)
	const int classIndex = net->Classify(imgCUDA, imgWidth, imgHeight, &confidence);
```

[`imageNet::Classify()`](../c/imageNet.h#L103) 接收GPU内存中的图像指针，并使用TensorRT进行推理；返回图像识别的对象类索引，以及结果的置信度值。

#### 结果解读

若[`imageNet::Classify()`](../c/imageNet.h#L103)没有返回错误, 将打印出已识别对象的分类信息。

``` cpp
	// make sure a valid classification result was returned	
	if( classIndex >= 0 )
	{
		// retrieve the name/description of the object class index
		const char* classDescription = net->GetClassDesc(classIndex);

		// print out the classification results
		printf("image is recognized as '%s' (class #%i) with %f%% confidence\n", 
			  classDescription, classIndex, confidence * 100.0f);
	}
	else
	{
		// if Classify() returned < 0, an error occurred
		printf("failed to classify image\n");
	}
```

[`imageNet::Classify()`](../c/imageNet.h#L103)返回了对象类的索引（ILSVRC12的类别编号是0和1000之间整数），可使用[`imageNet::GetClassDesc()`](../c/imageNet.h#L140) 函数来获取更详细的描述信息。

这1000个类的描述是在网络加载时，从[`ilsvrc12_synset_words.txt`](../data/networks/ilsvrc12_synset_words.txt) 解析出来的，这个文件是编译库时下载的。

#### 结束

在退出程序之前，`delete`网络对象来销毁TensorRT引擎并释放CUDA资源。

``` cpp
	// free the network's resources before shutting down
	delete net;

	// this is the end of the example!
	return 0;
}
```

## Creating CMakeLists.txt

接下来，使用CMake为识别程序创建一个makefile。在`~/my-recognition/CMakeLists.txt`中添加如下代码：

``` cmake
# require CMake 2.8 or greater
cmake_minimum_required(VERSION 2.8)

# declare my-recognition project
project(my-recognition)

# import jetson-inference and jetson-utils packages.
# note that if you didn't do "sudo make install"
# while building jetson-inference, this will error.
find_package(jetson-utils)
find_package(jetson-inference)

# CUDA and Qt4 are required
find_package(CUDA)
find_package(Qt4)

# setup Qt4 for build
include(${QT_USE_FILE})
add_definitions(${QT_DEFINITIONS})

# compile the my-recognition program
cuda_add_executable(my-recognition my-recognition.cpp)

# link my-recognition to jetson-inference library
target_link_libraries(my-recognition jetson-inference)
```

可以使用这个CMakeLists作为模板来编译我们自己使用`jetson-inference` 库的项目。关键点是：

*  引入`jetson-utils` 和 `jetson-inference` 项目:  
     ``` cmake
		find_package(jetson-utils)
		find_package(jetson-inference)
	```
*  链接`libjetson-inference`:  
     ``` cmake
		target_link_libraries(my-recognition jetson-inference)
	```

> **注意**:  这些库在执行`sudo make install`指令时安装到了`/usr/local/include`。 install是必要步骤，否则将提示找不到这些库文件。

## Building the Example

运行以下shell命令来编译`my-recognition`程序:  

``` bash
$ cd ~/my-recognition
$ cmake .
$ make
```

如果遇到错误，首先查看是否已运行`sudo make install`。

## Running the Example

下面用编译好的程序对测试图像进行分类：

``` bash
$ ./my-recognition polar_bear.jpg
image is recognized as 'ice bear, polar bear, Ursus Maritimus, Thalarctos maritimus' (class #296) with 99.999878% confidence
```
<img src="https://github.com/dusty-nv/jetson-inference/raw/master/data/images/polar_bear.jpg" width="400">

``` bash
$ ./my-recognition brown_bear.jpg
image is recognized as 'brown bear, bruin, Ursus arctos' (class #294) with 99.928925% confidence
```
<img src="https://github.com/dusty-nv/jetson-inference/raw/master/data/images/brown_bear.jpg" width="400">

``` bash
$ ./my-recognition black_bear.jpg
image is recognized as 'American black bear, black bear, Ursus americanus, Euarctos americanus' (class #295) with 98.898628% confidence
```
<img src="https://github.com/dusty-nv/jetson-inference/raw/master/data/images/black_bear.jpg" width="400">

This is the conclusion of this section of the tutorial.  Next, we'll classify a live video feed from the Jetson onboard camera.
